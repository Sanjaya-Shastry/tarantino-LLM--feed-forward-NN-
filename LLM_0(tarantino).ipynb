{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvNFNtkOat054bTt+R/vFz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sanjaya-Shastry/tarantino-LLM--feed-forward-NN-/blob/main/LLM_0(tarantino).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXDtfYzUxdZJ",
        "outputId": "4330d462-4846-49d2-a92b-f52c6b8eebf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-13 12:21:17--  https://raw.githubusercontent.com/Sanjaya-Shastry/tarantino-LLM--feed-forward-NN-/refs/heads/main/scripts.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 329361 (322K) [text/plain]\n",
            "Saving to: ‘scripts.txt.6’\n",
            "\n",
            "scripts.txt.6       100%[===================>] 321.64K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-07-13 12:21:17 (7.14 MB/s) - ‘scripts.txt.6’ saved [329361/329361]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/Sanjaya-Shastry/tarantino-LLM--feed-forward-NN-/refs/heads/main/scripts.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import layers"
      ],
      "metadata": {
        "id": "k0MhM3F65JMC"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('scripts.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "rNA8r7gX3L28"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = text.lower()"
      ],
      "metadata": {
        "id": "U0viRjuD3ZKO"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines = text.splitlines()\n",
        "cleaned_lines = [line.strip() for line in lines if line.strip() != '']\n",
        "cleaned_text = ' '.join(cleaned_lines)"
      ],
      "metadata": {
        "id": "AXB-MgMf3bI4"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_text[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-VONY7Bi37gZ",
        "outputId": "a5e16286-37d7-4273-f094-039892ae7df8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"django unchained written by quentin tarantino i ext - countryside - broiling hot day as the film's o\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "allowed_chars = set(string.ascii_letters + string.digits + \" .,\")\n",
        "cleaned_text= ''.join(char for char in cleaned_text if char in allowed_chars)"
      ],
      "metadata": {
        "id": "f7OmLXQY-JTu"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_text[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yv0UD2Gh-IOg",
        "outputId": "7af43521-a0e6-45eb-8ee0-2f6078486cd6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'django unchained written by quentin tarantino i ext  countryside  broiling hot day as the films open'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenization\n",
        "\n",
        "chars = sorted(set(cleaned_text))\n",
        "char_to_int = {ch: i for i, ch in enumerate(chars)}\n",
        "int_to_char = {i: ch for ch, i in char_to_int.items()}\n",
        "vocab_size = len(chars)"
      ],
      "metadata": {
        "id": "-M0DiU3p4sPe"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text = np.array([char_to_int[i] for i in cleaned_text], dtype=np.int32)"
      ],
      "metadata": {
        "id": "8LiSYlkG42uL"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(encoded_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBka1vjgVcjq",
        "outputId": "b38b1aea-d404-4d4e-f03c-3680a28c1c9e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "361467"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_size=16\n",
        "X=[]\n",
        "y=[]\n",
        "\n",
        "for i in range(len(encoded_text) - context_size):\n",
        "    X.append(encoded_text[i:i+context_size])\n",
        "    y.append(encoded_text[i+context_size])\n"
      ],
      "metadata": {
        "id": "Nm2hzFuK6o4e"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X= np.array(X)\n",
        "y= np.array(y)"
      ],
      "metadata": {
        "id": "-VNClSzK7GM0"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We want to convert these into vectors of dimension of len(vocab_size) i.e 39\n",
        "#embeddings\n",
        "\n",
        "X_embedded = np.zeros((len(X), context_size, vocab_size), dtype=np.float32)\n",
        "y_embedded = np.zeros((len(X), vocab_size), dtype=np.float32)\n",
        "\n",
        "for i in range(len(X)):\n",
        "    for t in range(context_size):\n",
        "        word_index = X[i][t]\n",
        "        X_embedded[i, t, word_index] = 1\n",
        "    y_embedded[i, y[i]] = 1\n"
      ],
      "metadata": {
        "id": "AE5aYLUt7orV"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_flat = X_embedded.reshape(len(X), context_size * vocab_size)\n"
      ],
      "metadata": {
        "id": "FYUfSMn1et2E"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Input(shape=(context_size * vocab_size,)),\n",
        "    keras.layers.Dense(512, activation='relu'),\n",
        "    keras.layers.Dense(256, activation='relu'),\n",
        "    keras.layers.Dense(vocab_size, activation='softmax')\n",
        "    ])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "bHhByr1gfhPs"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_flat, y_embedded, batch_size=128, epochs=10, validation_split=0.25)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRgpy7jlgMou",
        "outputId": "7c2f6796-9f9a-4272-e88a-c50e76b3d2a1"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 16ms/step - accuracy: 0.3615 - loss: 2.2175 - val_accuracy: 0.4310 - val_loss: 1.8941\n",
            "Epoch 2/10\n",
            "\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 16ms/step - accuracy: 0.5182 - loss: 1.5902 - val_accuracy: 0.4601 - val_loss: 1.8216\n",
            "Epoch 3/10\n",
            "\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 16ms/step - accuracy: 0.5723 - loss: 1.3942 - val_accuracy: 0.4653 - val_loss: 1.8144\n",
            "Epoch 4/10\n",
            "\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 16ms/step - accuracy: 0.6071 - loss: 1.2709 - val_accuracy: 0.4640 - val_loss: 1.8396\n",
            "Epoch 5/10\n",
            "\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 16ms/step - accuracy: 0.6380 - loss: 1.1681 - val_accuracy: 0.4681 - val_loss: 1.8791\n",
            "Epoch 6/10\n",
            "\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 15ms/step - accuracy: 0.6642 - loss: 1.0745 - val_accuracy: 0.4644 - val_loss: 1.9707\n",
            "Epoch 7/10\n",
            "\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 16ms/step - accuracy: 0.6845 - loss: 1.0053 - val_accuracy: 0.4640 - val_loss: 2.0386\n",
            "Epoch 8/10\n",
            "\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 15ms/step - accuracy: 0.7054 - loss: 0.9375 - val_accuracy: 0.4517 - val_loss: 2.1085\n",
            "Epoch 9/10\n",
            "\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 16ms/step - accuracy: 0.7210 - loss: 0.8818 - val_accuracy: 0.4512 - val_loss: 2.2006\n",
            "Epoch 10/10\n",
            "\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 16ms/step - accuracy: 0.7391 - loss: 0.8235 - val_accuracy: 0.4526 - val_loss: 2.2928\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f4e0c36b710>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"LLM_0(tarantino).keras\")"
      ],
      "metadata": {
        "id": "mNihgy0QgYaD"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(seed, length=300):\n",
        "    result = seed\n",
        "\n",
        "    for i in range(length):\n",
        "        cleaned_seed = ''.join([c for c in result.lower() if c in char_to_int])\n",
        "        seed_len = len(cleaned_seed)\n",
        "\n",
        "        if seed_len > context_size:\n",
        "            context = cleaned_seed[-context_size:]\n",
        "        elif seed_len < context_size:\n",
        "            padding = ' ' * (context_size - seed_len)\n",
        "            context = padding + cleaned_seed\n",
        "        else:\n",
        "            context = cleaned_seed\n",
        "\n",
        "        input_seq = [char_to_int.get(c, 0) for c in context]\n",
        "\n",
        "        x = np.zeros((1, context_size, vocab_size), dtype=np.float32)\n",
        "        for j, char_index in enumerate(input_seq):\n",
        "            x[0, j, char_index] = 1\n",
        "\n",
        "        x_flat = x.reshape(1, context_size * vocab_size)\n",
        "        preds = model.predict(x_flat, verbose=0)[0]\n",
        "        next_index = np.argmax(preds)\n",
        "        next_char = int_to_char[next_index]\n",
        "        result += next_char\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "nvMMuOq5kfpe"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text('Django was a',length=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lSHM3krHlXXl",
        "outputId": "13797c16-a683-4336-9115-b30fae18f580"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Django was a little bit be fuck i dooth, and smilly love count'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zOhc1xUtvCAw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}