{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOU9hkMUtSuEy3/FAZfSEBp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sanjaya-Shastry/tarantino-LLM-NN-/blob/main/LLM_0(tarantino).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXDtfYzUxdZJ",
        "outputId": "062a4246-ea1a-4890-fe7a-f8c3160a52ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-13 11:23:49--  https://raw.githubusercontent.com/Sanjaya-Shastry/tarantino-LLM-NN-/refs/heads/main/scripts.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 634257 (619K) [text/plain]\n",
            "Saving to: ‘scripts.txt.5’\n",
            "\n",
            "\rscripts.txt.5         0%[                    ]       0  --.-KB/s               \rscripts.txt.5       100%[===================>] 619.39K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-07-13 11:23:49 (10.8 MB/s) - ‘scripts.txt.5’ saved [634257/634257]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/Sanjaya-Shastry/tarantino-LLM-NN-/refs/heads/main/scripts.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import layers"
      ],
      "metadata": {
        "id": "k0MhM3F65JMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('scripts.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "rNA8r7gX3L28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = text.lower()"
      ],
      "metadata": {
        "id": "U0viRjuD3ZKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines = text.splitlines()\n",
        "cleaned_lines = [line.strip() for line in lines if line.strip() != '']\n",
        "cleaned_text = ' '.join(cleaned_lines)"
      ],
      "metadata": {
        "id": "AXB-MgMf3bI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_text[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-VONY7Bi37gZ",
        "outputId": "6f8ad35b-4433-49ef-9cc6-15748da6db55"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'django unchained written by quentin tarantino i ext  countryside  broiling hot day as the films open'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "allowed_chars = set(string.ascii_letters + string.digits + \" .,\")\n",
        "cleaned_text= ''.join(char for char in cleaned_text if char in allowed_chars)"
      ],
      "metadata": {
        "id": "f7OmLXQY-JTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_text[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yv0UD2Gh-IOg",
        "outputId": "fbe4d49a-0592-4218-e474-7f41b0bcbd23"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'django unchained written by quentin tarantino i ext  countryside  broiling hot day as the films open'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenization\n",
        "\n",
        "chars = sorted(set(cleaned_text))\n",
        "char_to_int = {ch: i for i, ch in enumerate(chars)}\n",
        "int_to_char = {i: ch for ch, i in char_to_int.items()}\n",
        "vocab_size = len(chars)"
      ],
      "metadata": {
        "id": "-M0DiU3p4sPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text = np.array([char_to_int[i] for i in cleaned_text], dtype=np.int32)"
      ],
      "metadata": {
        "id": "8LiSYlkG42uL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(encoded_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBka1vjgVcjq",
        "outputId": "f8dbcee3-8cde-4191-af80-e7334ec38f6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "361467"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_size=16\n",
        "X=[]\n",
        "y=[]\n",
        "\n",
        "for i in range(len(encoded_text) - context_size):\n",
        "    X.append(encoded_text[i:i+context_size])\n",
        "    y.append(encoded_text[i+context_size])\n"
      ],
      "metadata": {
        "id": "Nm2hzFuK6o4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X= np.array(X)\n",
        "y= np.array(y)"
      ],
      "metadata": {
        "id": "-VNClSzK7GM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We want to convert these into vectors of dimension of len(vocab_size) i.e 39\n",
        "#embeddings\n",
        "\n",
        "X_embedded = np.zeros((len(X), context_size, vocab_size), dtype=np.float32)\n",
        "y_embedded = np.zeros((len(X), vocab_size), dtype=np.float32)\n",
        "\n",
        "for i in range(len(X)):\n",
        "    for t in range(context_size):\n",
        "        word_index = X[i][t]\n",
        "        X_embedded[i, t, word_index] = 1\n",
        "    y_embedded[i, y[i]] = 1\n"
      ],
      "metadata": {
        "id": "AE5aYLUt7orV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_flat = X_embedded.reshape(len(X), context_size * vocab_size)\n"
      ],
      "metadata": {
        "id": "FYUfSMn1et2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Input(shape=(context_size * vocab_size,)),\n",
        "    keras.layers.Dense(512, activation='relu'),\n",
        "    keras.layers.Dense(256, activation='relu'),\n",
        "    keras.layers.Dense(vocab_size, activation='softmax')\n",
        "    ])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "bHhByr1gfhPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_flat, y_embedded, batch_size=128, epochs=10, validation_split=0.25)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRgpy7jlgMou",
        "outputId": "af00fb59-a7d7-478c-dd5c-ba41d91bbc0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.3615 - loss: 2.2170 - val_accuracy: 0.4287 - val_loss: 1.9095\n",
            "Epoch 2/10\n",
            "\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 17ms/step - accuracy: 0.5191 - loss: 1.5914 - val_accuracy: 0.4606 - val_loss: 1.8252\n",
            "Epoch 3/10\n",
            "\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.5721 - loss: 1.3977 - val_accuracy: 0.4664 - val_loss: 1.8204\n",
            "Epoch 4/10\n",
            "\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 16ms/step - accuracy: 0.6073 - loss: 1.2727 - val_accuracy: 0.4650 - val_loss: 1.8662\n",
            "Epoch 5/10\n",
            "\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.6365 - loss: 1.1708 - val_accuracy: 0.4642 - val_loss: 1.9167\n",
            "Epoch 6/10\n",
            "\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 15ms/step - accuracy: 0.6614 - loss: 1.0846 - val_accuracy: 0.4591 - val_loss: 1.9738\n",
            "Epoch 7/10\n",
            "\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 16ms/step - accuracy: 0.6839 - loss: 1.0081 - val_accuracy: 0.4560 - val_loss: 2.0558\n",
            "Epoch 8/10\n",
            "\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.7014 - loss: 0.9483 - val_accuracy: 0.4545 - val_loss: 2.1340\n",
            "Epoch 9/10\n",
            "\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 16ms/step - accuracy: 0.7205 - loss: 0.8873 - val_accuracy: 0.4515 - val_loss: 2.2315\n",
            "Epoch 10/10\n",
            "\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 17ms/step - accuracy: 0.7369 - loss: 0.8324 - val_accuracy: 0.4468 - val_loss: 2.3391\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f4e0ee2a490>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"LLM_0(tarantino).keras\")"
      ],
      "metadata": {
        "id": "mNihgy0QgYaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(seed, length=300):\n",
        "    result = seed\n",
        "\n",
        "    for i in range(length):\n",
        "        cleaned_seed = ''.join([c for c in result.lower() if c in char_to_int])\n",
        "        seed_len = len(cleaned_seed)\n",
        "\n",
        "        if seed_len > context_size:\n",
        "            context = cleaned_seed[-context_size:]\n",
        "        elif seed_len < context_size:\n",
        "            padding = ' ' * (context_size - seed_len)\n",
        "            context = padding + cleaned_seed\n",
        "        else:\n",
        "            context = cleaned_seed\n",
        "\n",
        "        input_seq = [char_to_int.get(c, 0) for c in context]\n",
        "\n",
        "        x = np.zeros((1, context_size, vocab_size), dtype=np.float32)\n",
        "        for j, char_index in enumerate(input_seq):\n",
        "            x[0, j, char_index] = 1\n",
        "\n",
        "        x_flat = x.reshape(1, context_size * vocab_size)\n",
        "        preds = model.predict(x_flat, verbose=0)[0]\n",
        "        next_index = np.argmax(preds)\n",
        "        next_char = int_to_char[next_index]\n",
        "        result += next_char\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "nvMMuOq5kfpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text('Broomhilda was',length=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lSHM3krHlXXl",
        "outputId": "fa39e16e-2591-4539-c2bd-979b481e834d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Broomhilda was a proat of a find them. she white men start with '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yi0NxNuvqrDM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}